{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(file):\n",
    "    if not Path(file).is_file():\n",
    "        url = \"http://yann.lecun.com/exdb/mnist/\" + file.name\n",
    "        with urllib.request.urlopen(url) as response, open(file, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response, out_file)\n",
    "\n",
    "    return np.frombuffer(gzip.open(file).read(), dtype=np.uint8).copy()\n",
    "\n",
    "\n",
    "def fetch_mnist():\n",
    "    dirname = Path(__file__).parent.resolve()\n",
    "    X_train = parse(dirname / \"mnist/train-images-idx3-ubyte.gz\")[\n",
    "        0x10:].reshape((-1, 28*28)).astype(np.float32)\n",
    "    Y_train = parse(dirname / \"mnist/train-labels-idx1-ubyte.gz\")[8:]\n",
    "    X_test = parse(dirname / \"mnist/t10k-images-idx3-ubyte.gz\")[\n",
    "        0x10:].reshape((-1, 28*28)).astype(np.float32)\n",
    "    Y_test = parse(dirname / \"mnist/t10k-labels-idx1-ubyte.gz\")[8:]\n",
    "    print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "\n",
    "\n",
    "def one_hot_encoding(Y):\n",
    "    n = len(Y)\n",
    "    Y_one_hot = np.zeros((n, 10))\n",
    "    Y_one_hot[np.arange(n), Y] = 1\n",
    "    return Y_one_hot\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "    Z -= np.max(Z, axis=1, keepdims=True)\n",
    "    e_Z = np.exp(Z)\n",
    "    A = e_Z / e_Z.sum(axis=1, keepdims=True)\n",
    "    return A\n",
    "\n",
    "\n",
    "def cross_entropy_loss(Y, Y_hat):\n",
    "    epsilon = 1e-10\n",
    "    return -np.sum(Y * np.log(Y_hat + epsilon)) / len(Y)\n",
    "\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(Z, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = fetch_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        Z1 = X.dot(self.W1) + self.b1\n",
    "        A1 = relu(Z1)\n",
    "        Z2 = A1.dot(self.W2) + self.b2\n",
    "        A2 = softmax(Z2)\n",
    "        return A2\n",
    "\n",
    "    def compute_loss(self, X, Y):\n",
    "        Y_hat = self.forward(X)\n",
    "        loss = cross_entropy_loss(Y, Y_hat)\n",
    "        return loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        Y_hat = self.forward(X)\n",
    "        return np.argmax(Y_hat, axis=1)\n",
    "\n",
    "    def compute_accuracy(self, X, Y):\n",
    "        predictions = self.predict(X)\n",
    "        correct = np.sum(predictions == np.argmax(Y, axis=1))\n",
    "        accuracy = correct / len(Y)\n",
    "        return accuracy\n",
    "\n",
    "    def backprop(self, X, Y, learning_rate=0.01):\n",
    "        Z1 = X.dot(self.W1) + self.b1\n",
    "        A1 = relu(Z1)\n",
    "        Z2 = A1.dot(self.W2) + self.b2\n",
    "        A2 = softmax(Z2)\n",
    "\n",
    "        m = len(X)\n",
    "        E2 = (A2 - Y) / m\n",
    "        dW2 = np.dot(A1.T, E2)\n",
    "        db2 = np.sum(E2, axis=0, keepdims=True)\n",
    "        E1 = np.dot(E2, self.W2.T)\n",
    "        E1[Z1 <= 0] = 0\n",
    "\n",
    "        X_reshaped = X.reshape(1, -1)\n",
    "        dW1 = np.dot(X_reshaped.T, E1)\n",
    "        db1 = np.sum(E1, axis=0, keepdims=True)\n",
    "\n",
    "        self.W1 -= learning_rate * dW1\n",
    "        self.b1 -= learning_rate * db1\n",
    "        self.W2 -= learning_rate * dW2\n",
    "        self.b2 -= learning_rate * db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(784, 100, 10)\n",
    "\n",
    "\n",
    "for epoch in (t := trange(10)):\n",
    "    running_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "\n",
    "    for i, data in enumerate(X_train):\n",
    "        X, Y = data, Y_train[i]\n",
    "        Y = one_hot_encoding([Y])\n",
    "        loss = net.compute_loss(X, Y)\n",
    "        running_loss += loss\n",
    "        net.backprop(X, Y, learning_rate=0.001)\n",
    "        accuracy = net.compute_accuracy(X, Y)\n",
    "        total_accuracy += accuracy\n",
    "\n",
    "    average_accuracy = total_accuracy / len(X_train)\n",
    "\n",
    "    t.set_description(\n",
    "        f'epoch: {epoch+1}, loss: {running_loss/len(X_train):.3f}, accuracy: {average_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in X_train:\n",
    "    X, Y = data, Y_train[i]\n",
    "    Y = one_hot_encoding([Y])\n",
    "    predictions = net.predict(X)\n",
    "    correct += np.sum(predictions == np.argmax(Y, axis=1))\n",
    "    total += len(Y)\n",
    "\n",
    "print('accuracy: %.3f' % (correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
